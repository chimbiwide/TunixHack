# TunixHack

Code for [chimbiwide](https://huggingface.co/chimbiwide) and [KeeganC](https://huggingface.co/KeeganC)'s [Google Tunix Hack](https://www.kaggle.com/competitions/google-tunix-hackathon/overview) hackathon submission.

---

### Quicklinks:

- ***[Hackathon Writeup](https://www.kaggle.com/competitions/google-tunix-hackathon/writeups/gemma3think)***
- ***[HuggingFace Article](https://huggingface.co/blog/chimbiwide/gemma3think)*** (more in-depth)
- ***[SFT-base model](https://huggingface.co/chimbiwide/gemma-3-1b-it-thinking-32k-sft-base)***
- ***[Final model](https://huggingface.co/chimbiwide/gemma-3-1b-it-thinking-32k-grpo-merged)*** (32k SFT + 28k GRPO)
- ***[32k Dataset](https://huggingface.co/datasets/chimbiwide/think-32k)***
- ***[Collection of Indivisual Datasets](https://huggingface.co/collections/npcLM/reasoning-datasets)***

---

### Introduction(-ish)

The goal is to use Google's new TPU based post-training library Tunix to teach Gemma3-1b to reason, not a new thing, but its a new library. 

As specified in the hackathon page, it's less focused on code and mathematics. So we put a bigger emphasis in creative writing and brainstorming (creative ideation).

For specific information about the models, visit our Huggingface page.

Please star/upvote if you like our work! 

---

### Repo Strucutre

